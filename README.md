# ğŸš¨ Agentic Fraud Detection System

A real-time fraud detection system using **5 AI Agents**, **Kafka Streams**, **KTable**, and **Velocity Windows** for detecting rapid-fire attacks.

![Architecture](https://img.shields.io/badge/Architecture-Kafka%20Streams-blue)
![Python](https://img.shields.io/badge/Python-3.10+-green)
![AI](https://img.shields.io/badge/AI-Gemini%20Flash-orange)

---

## ğŸ“‹ Table of Contents

- [Features](#-features)
- [Architecture](#-architecture)
- [Quick Start](#-quick-start)
- [Full Setup Guide](#-full-setup-guide)
- [Running the Demo](#-running-the-demo)
- [Viewing KTable Data](#-viewing-ktable-data)
- [Understanding the System](#-understanding-the-system)
- [Commands Reference](#-commands-reference)

---

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| **5 AI Agents** | BehaviorAnalyst, PatternDetector, GeographicAnalyst, RiskAssessor, TemporalAnalyst |
| **KTable** | RocksDB-backed state store for customer profiles and velocity tracking |
| **Velocity Windows** | 5-minute tumbling windows for rapid-fire attack detection |
| **Streaming Enrichment** | leftJoin operations to enrich transactions with customer context |
| **Intelligent Routing** | Auto-route to fraud-alerts, human-review, or approved-transactions |
| **GAN Mode** | AI vs AI adversarial training for improved detection |

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    KAFKA INPUT TOPICS                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  transactions   â”‚              customerProfiles                 â”‚
â”‚   (KStream)     â”‚                 (KStore)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                               â”‚
         â–¼                               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚  VELOCITY CALC  â”‚                      â”‚
â”‚  5-min window   â”‚                      â”‚
â”‚   (KStream)     â”‚                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
         â”‚                               â”‚
         â–¼                               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚Velocity Context â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚   (KTable)      â”‚
â”‚  RocksDB-backed â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              STREAMING ENRICHMENT LAYER                         â”‚
â”‚  Transaction + (leftJoin) Velocity + (leftJoin) CustomerProfile â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              5 AI AGENTS (Parallel Analysis)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Behavior   â”‚   Pattern   â”‚ Geographic  â”‚    Risk     â”‚Temporal â”‚
â”‚  Analyst    â”‚  Detector   â”‚  Analyst    â”‚  Assessor   â”‚ Analyst â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  INTELLIGENT ROUTING                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   fraud-alerts   â”‚   human-review   â”‚   approved-transactions   â”‚
â”‚   (>80% risk)    â”‚   (40-80% risk)  â”‚      (<40% risk)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

```bash
# 1. Clone and enter directory
cd c:\Users\mukun\Desktop\spa

# 2. Create virtual environment
python -m venv venv

# 3. Activate virtual environment (Windows)
venv\Scripts\activate

# 4. Install dependencies
pip install -r requirements.txt

# 5. Start Kafka (Docker required)
docker-compose up -d

# 6. Run the demo
python fraud_demo.py
```

---

## ğŸ“¦ Full Setup Guide

### Prerequisites

- **Python 3.10+**
- **Docker Desktop** (for Kafka)
- **Gemini API Key** (for AI agents)

### Step 1: Environment Setup

```bash
# Create virtual environment
python -m venv venv

# Activate (Windows PowerShell)
venv\Scripts\activate

# Activate (Windows CMD)
venv\Scripts\activate.bat

# Activate (Linux/Mac)
source venv/bin/activate
```

### Step 2: Install Dependencies

```bash
# Install all required packages
pip install -r requirements.txt

# Or install individually:
pip install kafka-python==2.0.2
pip install google-generativeai==0.3.2
pip install python-dotenv==1.0.0
pip install Faker==20.1.0
pip install colorama==0.4.6
pip install faust-streaming==0.10.19
pip install rocksdict
pip install flask==3.0.0
pip install requests==2.31.0
```

### Step 3: Configure API Key

Create a `.env` file:

```bash
# .env
GEMINI_API_KEY=your_gemini_api_key_here
KAFKA_BOOTSTRAP_SERVERS=localhost:9093
```

### Step 4: Start Kafka

```bash
# Start Kafka, Zookeeper, and Kafka UI
docker-compose up -d

# Verify containers are running
docker ps

# Expected output:
# - zookeeper (port 2181)
# - kafka (ports 9092, 9093)
# - kafka-ui (port 8080)
```

### Step 5: Create Kafka Topics (Optional)

```bash
# Topics are auto-created, but you can create manually:
python kafka_admin.py
```

---

## ğŸ® Running the Demo

### Main Demo (Interactive)

```bash
# Activate virtual environment first
venv\Scripts\activate

# Run the interactive demo
python fraud_demo.py
```

### Demo Scenarios

| Scenario | Description | Expected Result |
|----------|-------------|-----------------|
| **1. Normal Transaction** | â‚¹500 grocery purchase | âœ… APPROVED (low risk) |
| **2. High Velocity Attack** | 12 rapid transactions + â‚¹2,500 final | ğŸš¨ FRAUD DETECTED |
| **3. Unusual Amount Spike** | â‚¹150 avg â†’ â‚¹10,000 spike | âš ï¸ REVIEW |
| **4. AI vs AI (GAN Mode)** | Adversarial training loop | Learning both sides |

### GAN Dashboard

```bash
# Start the GAN training dashboard (optional)
python gan_dashboard.py

# View at: http://localhost:5001
```

---

## ğŸ“Š Viewing KTable Data

### View All KTable Contents

```bash
python view_ktable.py
```

**Example Output:**
```
ğŸ“Š KTABLE VIEWER
======================================================================

ğŸ“ˆ VELOCITY KTABLE (velocity_ktable)
----------------------------------------------------------------------
ğŸ”‘ Key: velocity:CUST_VELOCITY_001
   ğŸ“Š Transactions in window: 13
   ğŸ’° Total amount: â‚¹4,270.00
   ğŸª Unique merchants: 13
   â° Window: 23:00:15 â†’ 23:05:15

ğŸ‘¤ CUSTOMER PROFILE KTABLE (customer_profiles_ktable)
----------------------------------------------------------------------
ğŸ”‘ Key: profile:CUST_NORMAL_001
   ğŸ’° Avg Transaction: â‚¹500.00
   ğŸ“ Primary Location: Mumbai
   âš ï¸  Risk Level: LOW
```

### KTable Storage Location

```
ğŸ“‚ ktable_state/
   â”œâ”€â”€ velocity_ktable/           # Velocity tracking data
   â”‚   â”œâ”€â”€ CURRENT
   â”‚   â”œâ”€â”€ MANIFEST-*
   â”‚   â””â”€â”€ *.sst
   â””â”€â”€ customer_profiles_ktable/  # Customer profiles
       â”œâ”€â”€ CURRENT
       â”œâ”€â”€ MANIFEST-*
       â””â”€â”€ *.sst
```

---

## ğŸ§  Understanding the System

### KTable vs Kafka Topic

| Kafka Topic | KTable |
|-------------|--------|
| Log of all transactions | Current state per customer |
| Append-only | Updated in-place |
| Used for history/replay | Used for fast lookups |
| Like a diary | Like a scoreboard |

### Velocity Window (5-min Tumbling)

```python
# Thresholds for rapid-fire detection:
rapid_fire_detected = (
    transaction_count > 15 or      # >15 txns in 5 min
    velocity_score > 3.0 or        # >3 txns per minute
    (txn_count > 10 and merchants > 5)  # Card testing
)
```

### Streaming Enrichment (leftJoin)

```
Transaction â†’ leftJoin(Velocity) â†’ leftJoin(CustomerProfile) â†’ EnrichedTransaction
```

---

## ğŸ“ Commands Reference

### Environment Commands

```bash
# Create virtual environment
python -m venv venv

# Activate (Windows)
venv\Scripts\activate

# Deactivate
deactivate

# Install all dependencies
pip install -r requirements.txt
```

### Docker Commands

```bash
# Start Kafka stack
docker-compose up -d

# Stop Kafka stack
docker-compose down

# View logs
docker-compose logs -f kafka

# Check container status
docker ps
```

### Demo Commands

```bash
# Run interactive fraud demo
python fraud_demo.py

# View KTable contents
python view_ktable.py

# Start GAN dashboard
python gan_dashboard.py

# Run Kafka Streams worker (optional)
python kafka_streams.py worker -l info
```

### Admin Commands

```bash
# Create Kafka topics
python kafka_admin.py

# Test agents
python test_agents.py

# Test streaming context
python test_streaming_context.py

# Test production system
python test_production.py
```

---

## ğŸ“ Project Structure

```
spa/
â”œâ”€â”€ fraud_demo.py              # Main interactive demo
â”œâ”€â”€ production_coordinator.py  # 5-agent orchestrator
â”œâ”€â”€ velocity_ktable.py         # KTable implementation (RocksDB)
â”œâ”€â”€ streaming_context.py       # Original streaming context
â”œâ”€â”€ kafka_streams.py           # Faust Kafka Streams (optional)
â”œâ”€â”€ view_ktable.py            # KTable viewer utility
â”œâ”€â”€ intelligent_router.py     # Decision routing logic
â”œâ”€â”€ gan_dashboard.py          # GAN training visualization
â”œâ”€â”€ config.py                 # Configuration settings
â”œâ”€â”€ models.py                 # Data models
â”œâ”€â”€ knowledge_base.py         # Agent learning memory
â”‚
â”œâ”€â”€ agents/                   # AI Agent implementations
â”‚   â”œâ”€â”€ base_agent.py
â”‚   â”œâ”€â”€ behavior_analyst.py
â”‚   â”œâ”€â”€ pattern_detector_v2.py
â”‚   â”œâ”€â”€ geographic_analyst.py
â”‚   â”œâ”€â”€ risk_assessor.py
â”‚   â””â”€â”€ temporal_analyst.py
â”‚
â”œâ”€â”€ ktable_state/             # RocksDB storage (auto-created)
â”‚   â”œâ”€â”€ velocity_ktable/
â”‚   â””â”€â”€ customer_profiles_ktable/
â”‚
â”œâ”€â”€ docker-compose.yml        # Kafka Docker setup
â”œâ”€â”€ requirements.txt          # Python dependencies
â””â”€â”€ .env                      # API keys (create this)
```

---

## ğŸ”§ Troubleshooting

### Common Issues

| Issue | Solution |
|-------|----------|
| `ModuleNotFoundError: kafka` | Run `pip install kafka-python` |
| `RocksDB not available` | Run `pip install rocksdict` |
| `Kafka connection refused` | Start Docker: `docker-compose up -d` |
| `GEMINI_API_KEY not found` | Create `.env` file with your API key |

### Verify Setup

```bash
# Check Python version
python --version  # Should be 3.10+

# Check Docker
docker ps  # Should show kafka, zookeeper, kafka-ui

# Test Kafka connection
python -c "from kafka import KafkaProducer; print('Kafka OK')"

# Test RocksDB
python -c "from rocksdict import Rdict; print('RocksDB OK')"
```

---

## ğŸ”— URLs

| Service | URL |
|---------|-----|
| **Kafka UI** | http://localhost:8080 |
| **GAN Dashboard** | http://localhost:5001 |

---

## ğŸ“„ License

MIT License - Feel free to use and modify!

---

## ğŸ™ Acknowledgments

- **Google Gemini** - AI Agent intelligence
- **Apache Kafka** - Stream processing
- **RocksDB** - State store
- **Faust** - Python Kafka Streams

---

**Made with â¤ï¸ for fraud detection**
